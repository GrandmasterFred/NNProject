{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arlxaCUh5jFl"
   },
   "source": [
    "# This will setup the baseline experiment for the neural network. And subsequent improvements will be made on this network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gP7CEnsi8Gp4"
   },
   "source": [
    "This part sets up the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1692853607960,
     "user": {
      "displayName": "Kang Phan",
      "userId": "17382505543364018191"
     },
     "user_tz": -480
    },
    "id": "gWE4EXKe6aQl"
   },
   "outputs": [],
   "source": [
    "STUDENTID = 567     # this will be used for random states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14487,
     "status": "ok",
     "timestamp": 1692854163379,
     "user": {
      "displayName": "Kang Phan",
      "userId": "17382505543364018191"
     },
     "user_tz": -480
    },
    "id": "B7-VNPmt8E2m",
    "outputId": "1f1050da-e734-4407-d7c8-af006d3d6ecf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Number of training examples: 40000\n",
      "Number of validation examples: 10000\n",
      "Number of test examples: 10000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import logging\n",
    "from utils import *\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL Image to PyTorch Tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize the data\n",
    "])\n",
    "\n",
    "# define the label transformations, from int64 to float32\n",
    "transform_label = transforms.Compose([\n",
    "  #transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Download and load CIFAR-100 datasets\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True, target_transform=transform_label)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True, target_transform=transform_label)\n",
    "\n",
    "\n",
    "# Calculate the sizes for train, validation, and test sets\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "valid_size = len(train_dataset) - train_size\n",
    "\n",
    "# Split the train dataset into train and validation sets using a random seed\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [train_size, valid_size], generator=torch.Generator().manual_seed(STUDENTID))\n",
    "\n",
    "# Create data loaders for training, validation, and test sets\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(\"Number of training examples:\", len(train_dataset))\n",
    "print(\"Number of validation examples:\", len(valid_dataset))\n",
    "print(\"Number of test examples:\", len(test_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ec3Yt5GL_ydv"
   },
   "source": [
    "Setting up the train, evaluation, and test functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqEmAt8s8Eiu"
   },
   "source": [
    "Setting up the neural network model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-PaTAXyF6P7P"
   },
   "outputs": [],
   "source": [
    "# creating a model that automatically runs the forward function i guess, since it is easier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from utils import *\n",
    "from customModels import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training starts here\n",
      "currently at epoch 0 train accuracy: tensor(0.1425, device='cuda:0') loss of: 2.266914049911499 eval accuracy: tensor(0.1844, device='cuda:0')\n",
      "currently at epoch 1 train accuracy: tensor(0.2104, device='cuda:0') loss of: 2.13166695728302 eval accuracy: tensor(0.2289, device='cuda:0')\n",
      "currently at epoch 2 train accuracy: tensor(0.2450, device='cuda:0') loss of: 2.0480727083206176 eval accuracy: tensor(0.2675, device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [4], line 23\u001B[0m\n\u001B[0;32m     20\u001B[0m logger\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtraining starts here\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# training and saving model to dictionary\u001B[39;00m\n\u001B[1;32m---> 23\u001B[0m outputDict \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margDict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;66;03m# loading the best model, and then sending it off to testing\u001B[39;00m\n\u001B[0;32m     26\u001B[0m model \u001B[38;5;241m=\u001B[39m load_model_from_file(model, argDict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moutputName\u001B[39m\u001B[38;5;124m'\u001B[39m], argDict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moutputName\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[1;32mD:\\gitprojects\\NNProject\\utils.py:239\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, argDict, givenDataloader, evalDataloader, testDataloader)\u001B[0m\n\u001B[0;32m    236\u001B[0m accuracy_values \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    237\u001B[0m loss_values \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m--> 239\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx, (data, label) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(givenDataloader):\n\u001B[0;32m    240\u001B[0m     \u001B[38;5;66;03m#  this is captured inside a try because of some weird thing breaking in the middle sometimes when there is only 1 label\u001B[39;00m\n\u001B[0;32m    241\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    242\u001B[0m         data, label \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mto(device), label\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32mD:\\gitprojects\\FinerObjectDetectionVENV\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    625\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    626\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    627\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 628\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    629\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    631\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    632\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32mD:\\gitprojects\\FinerObjectDetectionVENV\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    669\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    670\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 671\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    672\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    673\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32mD:\\gitprojects\\FinerObjectDetectionVENV\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     56\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     57\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 58\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     59\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     60\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mD:\\gitprojects\\FinerObjectDetectionVENV\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     56\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     57\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 58\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     59\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     60\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mD:\\gitprojects\\FinerObjectDetectionVENV\\lib\\site-packages\\torch\\utils\\data\\dataset.py:295\u001B[0m, in \u001B[0;36mSubset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m    293\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(idx, \u001B[38;5;28mlist\u001B[39m):\n\u001B[0;32m    294\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[i] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m idx]]\n\u001B[1;32m--> 295\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\n",
      "File \u001B[1;32mD:\\gitprojects\\FinerObjectDetectionVENV\\lib\\site-packages\\torchvision\\datasets\\cifar.py:118\u001B[0m, in \u001B[0;36mCIFAR10.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m    115\u001B[0m img \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mfromarray(img)\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 118\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_transform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    121\u001B[0m     target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_transform(target)\n",
      "File \u001B[1;32mD:\\gitprojects\\FinerObjectDetectionVENV\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001B[0m, in \u001B[0;36mCompose.__call__\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[0;32m     94\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransforms:\n\u001B[1;32m---> 95\u001B[0m         img \u001B[38;5;241m=\u001B[39m \u001B[43mt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "File \u001B[1;32mD:\\gitprojects\\FinerObjectDetectionVENV\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\gitprojects\\FinerObjectDetectionVENV\\lib\\site-packages\\torchvision\\transforms\\transforms.py:270\u001B[0m, in \u001B[0;36mNormalize.forward\u001B[1;34m(self, tensor)\u001B[0m\n\u001B[0;32m    262\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, tensor: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m    263\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    264\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    268\u001B[0m \u001B[38;5;124;03m        Tensor: Normalized Tensor image.\u001B[39;00m\n\u001B[0;32m    269\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 270\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnormalize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minplace\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\gitprojects\\FinerObjectDetectionVENV\\lib\\site-packages\\torchvision\\transforms\\functional.py:360\u001B[0m, in \u001B[0;36mnormalize\u001B[1;34m(tensor, mean, std, inplace)\u001B[0m\n\u001B[0;32m    357\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(tensor, torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[0;32m    358\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimg should be Tensor Image. Got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(tensor)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 360\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF_t\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnormalize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmean\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minplace\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\gitprojects\\FinerObjectDetectionVENV\\lib\\site-packages\\torchvision\\transforms\\functional_tensor.py:934\u001B[0m, in \u001B[0;36mnormalize\u001B[1;34m(tensor, mean, std, inplace)\u001B[0m\n\u001B[0;32m    932\u001B[0m mean \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mas_tensor(mean, dtype\u001B[38;5;241m=\u001B[39mdtype, device\u001B[38;5;241m=\u001B[39mtensor\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m    933\u001B[0m std \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mas_tensor(std, dtype\u001B[38;5;241m=\u001B[39mdtype, device\u001B[38;5;241m=\u001B[39mtensor\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m--> 934\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43m(\u001B[49m\u001B[43mstd\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43many\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    935\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstd evaluated to zero after conversion to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdtype\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, leading to division by zero.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    936\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mean\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = ProjectNN()\n",
    "modelName = '1FirstModelTest'\n",
    "\n",
    "argDict = {\n",
    "  'lr': 0.001,\n",
    "  'maxEpoch': 250,\n",
    "  'idleEpoch': 25,\n",
    "  'outputName': modelName,\n",
    "  'optimizer': optim.SGD(model.parameters(), lr=0.001),\n",
    "  'criterion': nn.CrossEntropyLoss()\n",
    "}\n",
    "\n",
    "# setting up the logger\n",
    "loggerName = modelName + '.log'\n",
    "loggerName = os.path.join(argDict['outputName'], loggerName)\n",
    "logger = MyLogger(loggerName)\n",
    "argDict['logger'] = logger\n",
    "\n",
    "# just to initilalize the files\n",
    "logger.log('training starts here')\n",
    "\n",
    "# training and saving model to dictionary\n",
    "outputDict = train(model, argDict, train_loader, val_loader, test_loader)\n",
    "\n",
    "# loading the best model, and then sending it off to testing\n",
    "model = load_model_from_file(model, argDict['outputName'], argDict['outputName'])\n",
    "\n",
    "test_accuracy = test(model, argDict, test_loader)\n",
    "tempString = 'testing accuracy of ' + argDict['outputName'] + \" is: \" + str(test_accuracy)\n",
    "logger.log(tempString)\n",
    "\n",
    "argDict['test_accuracy'] = str(test_accuracy)\n",
    "save_dict_to_file(outputDict, argDict['outputName'], argDict['outputName'])\n",
    "\n",
    "del model\n",
    "del argDict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Define the folder you want to zip and the output zip file name\n",
    "folder_to_zip = modelName\n",
    "output_zip_file = modelName + \".zip\"\n",
    "\n",
    "# Use shutil.make_archive to create the zip file\n",
    "shutil.make_archive(output_zip_file, 'zip', folder_to_zip)\n",
    "\n",
    "os.rename(output_zip_file + '.zip', output_zip_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = NeuralNetwork()\n",
    "modelName = '2lowerLR'\n",
    "\n",
    "argDict = {\n",
    "  'lr': 0.0005,\n",
    "  'maxEpoch': 250,\n",
    "  'idleEpoch': 25,\n",
    "  'outputName': modelName,\n",
    "  'optimizer': optim.SGD(model.parameters(), lr=0.001),\n",
    "  'criterion': nn.CrossEntropyLoss()\n",
    "}\n",
    "\n",
    "# setting up the logger\n",
    "loggerName = modelName + '.log'\n",
    "loggerName = os.path.join(argDict['outputName'], loggerName)\n",
    "logger = MyLogger(loggerName)\n",
    "argDict['logger'] = logger\n",
    "\n",
    "# training and saving model to dictionary\n",
    "outputDict = train(model, argDict, train_loader, valid_loader, test_loader)\n",
    "save_dict_to_file(outputDict, argDict['outputName'], argDict['outputName'])\n",
    "\n",
    "# loading the best model, and then sending it off to testing\n",
    "model = load_model_from_file(model, argDict['outputName'], argDict['outputName'])\n",
    "\n",
    "test_accuracy = test(model, test_loader)\n",
    "tempString = 'testing accuracy of ' + argDict['outputName'] + \" is: \" + str(test_accuracy)\n",
    "logger.log(tempString)\n",
    "\n",
    "del model\n",
    "del argDict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = NeuralNetwork()\n",
    "modelName = '3rdHigherLR'\n",
    "\n",
    "argDict = {\n",
    "  'lr': 0.003,\n",
    "  'maxEpoch': 250,\n",
    "  'idleEpoch': 25,\n",
    "  'outputName': modelName,\n",
    "  'optimizer': optim.SGD(model.parameters(), lr=0.001),\n",
    "  'criterion': nn.CrossEntropyLoss()\n",
    "}\n",
    "\n",
    "# setting up the logger\n",
    "loggerName = modelName + '.log'\n",
    "loggerName = os.path.join(argDict['outputName'], loggerName)\n",
    "logger = MyLogger(loggerName)\n",
    "argDict['logger'] = logger\n",
    "\n",
    "# training and saving model to dictionary\n",
    "outputDict = train(model, argDict, train_loader, valid_loader, test_loader)\n",
    "save_dict_to_file(outputDict, argDict['outputName'], argDict['outputName'])\n",
    "\n",
    "# loading the best model, and then sending it off to testing\n",
    "model = load_model_from_file(model, argDict['outputName'], argDict['outputName'])\n",
    "\n",
    "test_accuracy = test(model, test_loader)\n",
    "tempString = 'testing accuracy of ' + argDict['outputName'] + \" is: \" + str(test_accuracy)\n",
    "logger.log(tempString)\n",
    "\n",
    "del model\n",
    "del argDict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('finished.txt', \"w\") as file:\n",
    "  file.write('donezo')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMPhCe+CPqr8788BodV/T4I",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}