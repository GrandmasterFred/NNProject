{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    " # this file will try to trian the two models defined here. And determine which is the best performing one"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "InceptionModel3                               [64, 10]                  --\n",
      "├─Sequential: 1-1                             [64, 32, 32, 32]          --\n",
      "│    └─Conv2d_BN: 2-1                         [64, 32, 32, 32]          --\n",
      "│    │    └─Sequential: 3-1                   [64, 32, 32, 32]          928\n",
      "├─Sequential: 1-47                            --                        (recursive)\n",
      "│    └─Conv2d_BN: 2-47                        --                        (recursive)\n",
      "│    │    └─Sequential: 3-48                  --                        (recursive)\n",
      "├─Sequential: 1-3                             [64, 64, 32, 32]          --\n",
      "│    └─Conv2d_BN: 2-3                         [64, 64, 32, 32]          --\n",
      "│    │    └─Sequential: 3-3                   [64, 64, 32, 32]          18,560\n",
      "├─Sequential: 1-47                            --                        (recursive)\n",
      "│    └─Conv2d_BN: 2-47                        --                        (recursive)\n",
      "│    │    └─Sequential: 3-48                  --                        (recursive)\n",
      "├─InceptionA: 1-5                             [64, 240, 32, 32]         224,000\n",
      "│    └─Conv2d_BN: 2-5                         [64, 64, 32, 32]          --\n",
      "│    │    └─Sequential: 3-5                   [64, 64, 32, 32]          4,224\n",
      "├─Sequential: 1-47                            --                        (recursive)\n",
      "│    └─Conv2d_BN: 2-47                        --                        (recursive)\n",
      "│    │    └─Sequential: 3-48                  --                        (recursive)\n",
      "├─InceptionA: 1-17                            --                        (recursive)\n",
      "│    └─Sequential: 2-7                        [64, 64, 32, 32]          76,928\n",
      "│    │    └─Conv2d_BN: 3-7                    [64, 48, 32, 32]          3,168\n",
      "├─Sequential: 1-47                            --                        (recursive)\n",
      "│    └─Conv2d_BN: 2-47                        --                        (recursive)\n",
      "│    │    └─Sequential: 3-48                  --                        (recursive)\n",
      "├─InceptionA: 1-17                            --                        (recursive)\n",
      "│    └─Sequential: 2-9                        --                        (recursive)\n",
      "│    │    └─Conv2d_BN: 3-9                    [64, 64, 32, 32]          76,928\n",
      "├─Sequential: 1-47                            --                        (recursive)\n",
      "│    └─Conv2d_BN: 2-47                        --                        (recursive)\n",
      "│    │    └─Sequential: 3-48                  --                        (recursive)\n",
      "├─InceptionA: 1-17                            --                        (recursive)\n",
      "│    └─Sequential: 2-11                       [64, 96, 32, 32]          138,624\n",
      "│    │    └─Conv2d_BN: 3-11                   [64, 64, 32, 32]          4,224\n",
      "├─Sequential: 1-47                            --                        (recursive)\n",
      "│    └─Conv2d_BN: 2-47                        --                        (recursive)\n",
      "│    │    └─Sequential: 3-48                  --                        (recursive)\n",
      "├─InceptionA: 1-17                            --                        (recursive)\n",
      "│    └─Sequential: 2-15                       --                        (recursive)\n",
      "│    │    └─Conv2d_BN: 3-13                   [64, 96, 32, 32]          55,488\n",
      "├─Sequential: 1-47                            --                        (recursive)\n",
      "│    └─Conv2d_BN: 2-47                        --                        (recursive)\n",
      "│    │    └─Sequential: 3-48                  --                        (recursive)\n",
      "├─InceptionA: 1-17                            --                        (recursive)\n",
      "│    └─Sequential: 2-15                       --                        (recursive)\n",
      "│    │    └─Conv2d_BN: 3-15                   [64, 96, 32, 32]          83,136\n",
      "├─Sequential: 1-47                            --                        (recursive)\n",
      "│    └─Conv2d_BN: 2-47                        --                        (recursive)\n",
      "│    │    └─Sequential: 3-48                  --                        (recursive)\n",
      "├─InceptionA: 1-17                            --                        (recursive)\n",
      "│    └─Sequential: 2-17                       [64, 16, 32, 32]          --\n",
      "│    │    └─AvgPool2d: 3-17                   [64, 64, 32, 32]          --\n",
      "│    │    └─Conv2d_BN: 3-18                   [64, 16, 32, 32]          1,056\n",
      "├─Sequential: 1-47                            --                        (recursive)\n",
      "│    └─Conv2d_BN: 2-47                        --                        (recursive)\n",
      "│    │    └─Sequential: 3-48                  --                        (recursive)\n",
      "├─InceptionB: 1-19                            [64, 720, 16, 16]         154,112\n",
      "│    └─Conv2d_BN: 2-19                        [64, 384, 16, 16]         --\n",
      "│    │    └─Sequential: 3-20                  [64, 384, 16, 16]         830,208\n",
      "├─Sequential: 1-47                            --                        (recursive)\n",
      "│    └─Conv2d_BN: 2-47                        --                        (recursive)\n",
      "│    │    └─Sequential: 3-48                  --                        (recursive)\n",
      "├─InceptionB: 1-27                            --                        (recursive)\n",
      "│    └─Sequential: 2-21                       [64, 96, 16, 16]          138,624\n",
      "│    │    └─Conv2d_BN: 3-22                   [64, 64, 32, 32]          15,488\n",
      "├─Sequential: 1-47                            --                        (recursive)\n",
      "│    └─Conv2d_BN: 2-47                        --                        (recursive)\n",
      "│    │    └─Sequential: 3-48                  --                        (recursive)\n",
      "├─InceptionB: 1-27                            --                        (recursive)\n",
      "│    └─Sequential: 2-25                       --                        (recursive)\n",
      "│    │    └─Conv2d_BN: 3-24                   [64, 96, 32, 32]          55,488\n",
      "├─Sequential: 1-47                            --                        (recursive)\n",
      "│    └─Conv2d_BN: 2-47                        --                        (recursive)\n",
      "│    │    └─Sequential: 3-48                  --                        (recursive)\n",
      "├─InceptionB: 1-27                            --                        (recursive)\n",
      "│    └─Sequential: 2-25                       --                        (recursive)\n",
      "│    │    └─Conv2d_BN: 3-26                   [64, 96, 16, 16]          83,136\n",
      "├─Sequential: 1-47                            --                        (recursive)\n",
      "│    └─Conv2d_BN: 2-47                        --                        (recursive)\n",
      "│    │    └─Sequential: 3-48                  --                        (recursive)\n",
      "├─InceptionB: 1-27                            --                        (recursive)\n",
      "│    └─MaxPool2d: 2-27                        [64, 240, 16, 16]         --\n",
      "├─InceptionC: 1-28                            [64, 768, 16, 16]         1,128,064\n",
      "│    └─Conv2d_BN: 2-28                        [64, 192, 16, 16]         --\n",
      "│    │    └─Sequential: 3-28                  [64, 192, 16, 16]         138,624\n",
      "├─Sequential: 1-47                            --                        (recursive)\n",
      "│    └─Conv2d_BN: 2-47                        --                        (recursive)\n",
      "│    │    └─Sequential: 3-48                  --                        (recursive)\n",
      "├─InceptionC: 1-46                            --                        (recursive)\n",
      "│    └─Sequential: 2-30                       [64, 192, 16, 16]         287,360\n",
      "│    │    └─Conv2d_BN: 3-30                   [64, 128, 16, 16]         92,416\n",
      "├─Sequential: 1-47                            --                        (recursive)\n",
      "│    └─Conv2d_BN: 2-47                        --                        (recursive)\n",
      "│    │    └─Sequential: 3-48                  --                        (recursive)\n",
      "├─InceptionC: 1-46                            --                        (recursive)\n",
      "│    └─Sequential: 2-34                       --                        (recursive)\n",
      "│    │    └─Conv2d_BN: 3-32                   [64, 128, 16, 16]         114,944\n",
      "├─Sequential: 1-47                            --                        (recursive)\n",
      "│    └─Conv2d_BN: 2-47                        --                        (recursive)\n",
      "│    │    └─Sequential: 3-48                  --                        (recursive)\n",
      "├─InceptionC: 1-46                            --                        (recursive)\n",
      "│    └─Sequential: 2-34                       --                        (recursive)\n",
      "│    │    └─Conv2d_BN: 3-34                   [64, 192, 16, 16]         172,416\n",
      "├─Sequential: 1-47                            --                        (recursive)\n",
      "│    └─Conv2d_BN: 2-47                        --                        (recursive)\n",
      "│    │    └─Sequential: 3-48                  --                        (recursive)\n",
      "├─InceptionC: 1-46                            --                        (recursive)\n",
      "│    └─Sequential: 2-36                       [64, 192, 16, 16]         517,248\n",
      "│    │    └─Conv2d_BN: 3-36                   [64, 128, 16, 16]         92,416\n",
      "├─Sequential: 1-47                            --                        (recursive)\n",
      "│    └─Conv2d_BN: 2-47                        --                        (recursive)\n",
      "│    │    └─Sequential: 3-48                  --                        (recursive)\n",
      "├─InceptionC: 1-46                            --                        (recursive)\n",
      "│    └─Sequential: 2-44                       --                        (recursive)\n",
      "│    │    └─Conv2d_BN: 3-38                   [64, 128, 16, 16]         114,944\n",
      "├─Sequential: 1-47                            --                        (recursive)\n",
      "│    └─Conv2d_BN: 2-47                        --                        (recursive)\n",
      "│    │    └─Sequential: 3-48                  --                        (recursive)\n",
      "├─InceptionC: 1-46                            --                        (recursive)\n",
      "│    └─Sequential: 2-44                       --                        (recursive)\n",
      "│    │    └─Conv2d_BN: 3-40                   [64, 128, 16, 16]         114,944\n",
      "├─Sequential: 1-47                            --                        (recursive)\n",
      "│    └─Conv2d_BN: 2-47                        --                        (recursive)\n",
      "│    │    └─Sequential: 3-48                  --                        (recursive)\n",
      "├─InceptionC: 1-46                            --                        (recursive)\n",
      "│    └─Sequential: 2-44                       --                        (recursive)\n",
      "│    │    └─Conv2d_BN: 3-42                   [64, 128, 16, 16]         114,944\n",
      "├─Sequential: 1-47                            --                        (recursive)\n",
      "│    └─Conv2d_BN: 2-47                        --                        (recursive)\n",
      "│    │    └─Sequential: 3-48                  --                        (recursive)\n",
      "├─InceptionC: 1-46                            --                        (recursive)\n",
      "│    └─Sequential: 2-44                       --                        (recursive)\n",
      "│    │    └─Conv2d_BN: 3-44                   [64, 192, 16, 16]         172,416\n",
      "├─Sequential: 1-47                            --                        (recursive)\n",
      "│    └─Conv2d_BN: 2-47                        --                        (recursive)\n",
      "│    │    └─Sequential: 3-48                  --                        (recursive)\n",
      "├─InceptionC: 1-46                            --                        (recursive)\n",
      "│    └─Sequential: 2-46                       [64, 192, 16, 16]         --\n",
      "│    │    └─AvgPool2d: 3-46                   [64, 720, 16, 16]         --\n",
      "│    │    └─Conv2d_BN: 3-47                   [64, 192, 16, 16]         138,624\n",
      "├─Sequential: 1-47                            --                        (recursive)\n",
      "│    └─Conv2d_BN: 2-47                        --                        (recursive)\n",
      "│    │    └─Sequential: 3-48                  --                        (recursive)\n",
      "├─Sequential: 1-48                            [64, 320, 1, 1]           --\n",
      "│    └─Conv2d_BN: 2-48                        [64, 320, 16, 16]         --\n",
      "│    │    └─Sequential: 3-49                  [64, 320, 16, 16]         246,400\n",
      "│    └─AdaptiveAvgPool2d: 2-49                [64, 320, 1, 1]           --\n",
      "│    └─Dropout: 2-50                          [64, 320, 1, 1]           --\n",
      "├─Linear: 1-49                                [64, 10]                  3,210\n",
      "===============================================================================================\n",
      "Total params: 5,413,290\n",
      "Trainable params: 5,413,290\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 60.47\n",
      "===============================================================================================\n",
      "Input size (MB): 0.79\n",
      "Forward/backward pass size (MB): 1350.57\n",
      "Params size (MB): 10.99\n",
      "Estimated Total Size (MB): 1362.35\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Module, Sequential, LeakyReLU, Conv2d, BatchNorm2d, AvgPool2d, MaxPool2d, AdaptiveAvgPool2d, Linear, Dropout\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "from customModelsInception import *\n",
    "\n",
    "# this is adapted from https://github.com/Moeo3/GoogLeNet-Inception-V3-pytorch/blob/master/googlenet_v3.py#L58 with its size modified to suit the CIFAR10 dataset instead of the origianl ImageNet dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Number of training examples: 40000\n",
      "Number of validation examples: 10000\n",
      "Number of test examples: 10000\n"
     ]
    }
   ],
   "source": [
    "STUDENTID = 567     # this will be used for random states\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import logging\n",
    "from utils import *\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL Image to PyTorch Tensor\n",
    "    # this normalization is industry standard, it seems\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))  # Normalize the data\n",
    "])\n",
    "\n",
    "\n",
    "# define the label transformations, from int64 to float32\n",
    "transform_label = transforms.Compose([\n",
    "    #transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Download and load CIFAR-100 datasets\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True, target_transform=transform_label)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True, target_transform=transform_label)\n",
    "\n",
    "\n",
    "# Calculate the sizes for train, validation, and test sets\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "valid_size = len(train_dataset) - train_size\n",
    "\n",
    "# Split the train dataset into train and validation sets using a random seed\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [train_size, valid_size], generator=torch.Generator().manual_seed(STUDENTID))\n",
    "\n",
    "# Create data loaders for training, validation, and test sets\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(\"Number of training examples:\", len(train_dataset))\n",
    "print(\"Number of validation examples:\", len(valid_dataset))\n",
    "print(\"Number of test examples:\", len(test_dataset))\n",
    "\n",
    "# creating a model that automatically runs the forward function i guess, since it is easier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from utils import *\n",
    "from customModels import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = InceptionModel3(channels_in=3, class_num=10)\n",
    "modelName = 'InceptionModel3_base'\n",
    "\n",
    "# this transformation sequence must be modified to work with the random stuff\n",
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL Image to PyTorch Tensor\n",
    "    # this normalization is industry standard, it seems\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))  # Normalize the data\n",
    "])\n",
    "\n",
    "argDict = {\n",
    "    'lr': 0.001,\n",
    "    'maxEpoch': 250,\n",
    "    'idleEpoch': 25,\n",
    "    'outputName': modelName,\n",
    "    'optimizer': optim.SGD(model.parameters(), lr=0.001),\n",
    "    'criterion': nn.CrossEntropyLoss()\n",
    "}\n",
    "\n",
    "STUDENTID = 567     # this will be used for random states\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import logging\n",
    "from utils import *\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "# define the label transformations, from int64 to float32\n",
    "transform_label = transforms.Compose([\n",
    "    #transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Download and load CIFAR-100 datasets\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True, target_transform=transform_label)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True, target_transform=transform_label)\n",
    "\n",
    "\n",
    "# Calculate the sizes for train, validation, and test sets\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "valid_size = len(train_dataset) - train_size\n",
    "\n",
    "# Split the train dataset into train and validation sets using a random seed\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [train_size, valid_size], generator=torch.Generator().manual_seed(STUDENTID))\n",
    "\n",
    "# Create data loaders for training, validation, and test sets\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(\"Number of training examples:\", len(train_dataset))\n",
    "print(\"Number of validation examples:\", len(valid_dataset))\n",
    "print(\"Number of test examples:\", len(test_dataset))\n",
    "\n",
    "# creating a model that automatically runs the forward function i guess, since it is easier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from utils import *\n",
    "from customModels import *\n",
    "\n",
    "# setting up the logger\n",
    "loggerName = modelName + '.log'\n",
    "loggerName = os.path.join(argDict['outputName'], loggerName)\n",
    "logger = MyLogger(loggerName)\n",
    "argDict['logger'] = logger\n",
    "\n",
    "# just to initilalize the files\n",
    "logger.log('training starts here')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# training and saving model to dictionary\n",
    "outputDict = train(model, argDict, train_loader, val_loader, test_loader)\n",
    "\n",
    "# loading the best model, and then sending it off to testing\n",
    "model = load_model_from_file(model, argDict['outputName'], argDict['outputName'])\n",
    "\n",
    "test_accuracy = test(model, argDict, test_loader)\n",
    "tempString = 'testing accuracy of ' + argDict['outputName'] + \" is: \" + str(test_accuracy)\n",
    "logger.log(tempString)\n",
    "\n",
    "argDict['test_accuracy'] = str(test_accuracy)\n",
    "\n",
    "# timing the thing as well\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "argDict['time_taken'] = execution_time\n",
    "save_dict_to_file(outputDict, argDict['outputName'], argDict['outputName'])\n",
    "\n",
    "del model\n",
    "del argDict\n",
    "\n",
    "# Define the folder you want to zip and the output zip file name\n",
    "folder_to_zip = modelName\n",
    "output_zip_file = modelName + \".zip\"\n",
    "\n",
    "# Use shutil.make_archive to create the zip file\n",
    "shutil.make_archive(output_zip_file, 'zip', folder_to_zip)\n",
    "\n",
    "os.rename(output_zip_file + '.zip', output_zip_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}