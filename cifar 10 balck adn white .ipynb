{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arlxaCUh5jFl"
   },
   "source": [
    "# This file will run the black and white version of the testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gP7CEnsi8Gp4"
   },
   "source": [
    "This part sets up the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1692853607960,
     "user": {
      "displayName": "Kang Phan",
      "userId": "17382505543364018191"
     },
     "user_tz": -480
    },
    "id": "gWE4EXKe6aQl"
   },
   "outputs": [],
   "source": [
    "STUDENTID = 567     # this will be used for random states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14487,
     "status": "ok",
     "timestamp": 1692854163379,
     "user": {
      "displayName": "Kang Phan",
      "userId": "17382505543364018191"
     },
     "user_tz": -480
    },
    "id": "B7-VNPmt8E2m",
    "outputId": "1f1050da-e734-4407-d7c8-af006d3d6ecf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Number of training examples: 40000\n",
      "Number of validation examples: 10000\n",
      "Number of test examples: 10000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import logging\n",
    "from utils import *\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "# Define data transformations\n",
    "# this one adds the grayscale transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL Image to PyTorch Tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # Normalize the data\n",
    "    transforms.Grayscale()\n",
    "])\n",
    "\n",
    "# Download and load CIFAR-100 datasets\n",
    "train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "\n",
    "# Calculate the sizes for train, validation, and test sets\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "valid_size = len(train_dataset) - train_size\n",
    "\n",
    "# Split the train dataset into train and validation sets using a random seed\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [train_size, valid_size], generator=torch.Generator().manual_seed(STUDENTID))\n",
    "\n",
    "# Create data loaders for training, validation, and test sets\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(\"Number of training examples:\", len(train_dataset))\n",
    "print(\"Number of validation examples:\", len(valid_dataset))\n",
    "print(\"Number of test examples:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqEmAt8s8Eiu"
   },
   "source": [
    "Setting up the neural network model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "for idx, data in enumerate(train_loader):\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "define the self\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "BlackAndWhiteNN                          [64, 100]                 --\n",
      "├─Sequential: 1-1                        [64, 192, 1, 1]           --\n",
      "│    └─Conv2d: 2-1                       [64, 64, 9, 9]            640\n",
      "│    └─ReLU: 2-2                         [64, 64, 9, 9]            --\n",
      "│    └─BatchNorm2d: 2-3                  [64, 64, 9, 9]            128\n",
      "│    └─MaxPool2d: 2-4                    [64, 64, 4, 4]            --\n",
      "│    └─Conv2d: 2-5                       [64, 192, 4, 4]           110,784\n",
      "│    └─ReLU: 2-6                         [64, 192, 4, 4]           --\n",
      "│    └─BatchNorm2d: 2-7                  [64, 192, 4, 4]           384\n",
      "│    └─Conv2d: 2-8                       [64, 192, 4, 4]           331,968\n",
      "│    └─ReLU: 2-9                         [64, 192, 4, 4]           --\n",
      "│    └─BatchNorm2d: 2-10                 [64, 192, 4, 4]           384\n",
      "│    └─MaxPool2d: 2-11                   [64, 192, 1, 1]           --\n",
      "├─AdaptiveAvgPool2d: 1-2                 [64, 192, 6, 6]           --\n",
      "├─Sequential: 1-3                        [64, 100]                 --\n",
      "│    └─Dropout: 2-12                     [64, 6912]                --\n",
      "│    └─Linear: 2-13                      [64, 4096]                28,315,648\n",
      "│    └─ReLU: 2-14                        [64, 4096]                --\n",
      "│    └─Dropout: 2-15                     [64, 4096]                --\n",
      "│    └─Linear: 2-16                      [64, 4096]                16,781,312\n",
      "│    └─ReLU: 2-17                        [64, 4096]                --\n",
      "│    └─Linear: 2-18                      [64, 100]                 409,700\n",
      "==========================================================================================\n",
      "Total params: 45,950,948\n",
      "Trainable params: 45,950,948\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 3.37\n",
      "==========================================================================================\n",
      "Input size (MB): 0.26\n",
      "Forward/backward pass size (MB): 15.85\n",
      "Params size (MB): 183.80\n",
      "Estimated Total Size (MB): 199.91\n",
      "==========================================================================================\n",
      "define the self\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "NeuralNetwork                            [64, 100]                 --\n",
      "├─Sequential: 1-1                        [64, 192, 1, 1]           --\n",
      "│    └─Conv2d: 2-1                       [64, 64, 9, 9]            1,792\n",
      "│    └─ReLU: 2-2                         [64, 64, 9, 9]            --\n",
      "│    └─BatchNorm2d: 2-3                  [64, 64, 9, 9]            128\n",
      "│    └─MaxPool2d: 2-4                    [64, 64, 4, 4]            --\n",
      "│    └─Conv2d: 2-5                       [64, 192, 4, 4]           110,784\n",
      "│    └─ReLU: 2-6                         [64, 192, 4, 4]           --\n",
      "│    └─BatchNorm2d: 2-7                  [64, 192, 4, 4]           384\n",
      "│    └─Conv2d: 2-8                       [64, 192, 4, 4]           331,968\n",
      "│    └─ReLU: 2-9                         [64, 192, 4, 4]           --\n",
      "│    └─BatchNorm2d: 2-10                 [64, 192, 4, 4]           384\n",
      "│    └─MaxPool2d: 2-11                   [64, 192, 1, 1]           --\n",
      "├─AdaptiveAvgPool2d: 1-2                 [64, 192, 6, 6]           --\n",
      "├─Sequential: 1-3                        [64, 100]                 --\n",
      "│    └─Dropout: 2-12                     [64, 6912]                --\n",
      "│    └─Linear: 2-13                      [64, 4096]                28,315,648\n",
      "│    └─ReLU: 2-14                        [64, 4096]                --\n",
      "│    └─Dropout: 2-15                     [64, 4096]                --\n",
      "│    └─Linear: 2-16                      [64, 4096]                16,781,312\n",
      "│    └─ReLU: 2-17                        [64, 4096]                --\n",
      "│    └─Linear: 2-18                      [64, 100]                 409,700\n",
      "==========================================================================================\n",
      "Total params: 45,952,100\n",
      "Trainable params: 45,952,100\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 3.38\n",
      "==========================================================================================\n",
      "Input size (MB): 0.79\n",
      "Forward/backward pass size (MB): 15.85\n",
      "Params size (MB): 183.81\n",
      "Estimated Total Size (MB): 200.44\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# everything inside util is needed i guess\n",
    "from utils import *\n",
    "from customModels import BlackAndWhiteNN, NeuralNetwork\n",
    "from torchinfo import summary\n",
    "\n",
    "if True:\n",
    "    model = BlackAndWhiteNN()\n",
    "    print(summary(model, (64, 1, 32, 32)))\n",
    "\n",
    "    model = NeuralNetwork()\n",
    "    print(summary(model, (64, 3, 32, 32)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "define the self\n",
      "currently at epoch 0 train accuracy: tensor(0.0144, device='cuda:0') loss of: 4.603961315155029 eval accuracy: tensor(0.0222, device='cuda:0')\n",
      "currently at epoch 1 train accuracy: tensor(0.0304, device='cuda:0') loss of: 4.499137261199952 eval accuracy: tensor(0.0350, device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [6], line 116\u001B[0m\n\u001B[0;32m    113\u001B[0m argDict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlogger\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m logger\n\u001B[0;32m    115\u001B[0m \u001B[38;5;66;03m# training and saving model to dictionary\u001B[39;00m\n\u001B[1;32m--> 116\u001B[0m outputDict \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margDict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    117\u001B[0m save_dict_to_file(outputDict, argDict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moutputName\u001B[39m\u001B[38;5;124m'\u001B[39m], argDict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moutputName\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m    119\u001B[0m \u001B[38;5;66;03m# loading the best model, and then sending it off to testing\u001B[39;00m\n",
      "Cell \u001B[1;32mIn [6], line 95\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, argDict, givenDataloader, evalDataloader, testDataloader)\u001B[0m\n\u001B[0;32m     92\u001B[0m argDict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrainingStopEpoch\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m currentEpoch\n\u001B[0;32m     94\u001B[0m \u001B[38;5;66;03m# saves the dictionary as well\u001B[39;00m\n\u001B[1;32m---> 95\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43margDict\u001B[49m\n",
      "Cell \u001B[1;32mIn [6], line 95\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, argDict, givenDataloader, evalDataloader, testDataloader)\u001B[0m\n\u001B[0;32m     92\u001B[0m argDict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrainingStopEpoch\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m currentEpoch\n\u001B[0;32m     94\u001B[0m \u001B[38;5;66;03m# saves the dictionary as well\u001B[39;00m\n\u001B[1;32m---> 95\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43margDict\u001B[49m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:1180\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:621\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:930\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:921\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:318\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\DataSpell 2021.3.3\\plugins\\python-ce\\helpers\\pydev\\pydevd.py:1147\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1144\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1147\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\DataSpell 2021.3.3\\plugins\\python-ce\\helpers\\pydev\\pydevd.py:1162\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1159\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1161\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1162\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1164\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1166\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = BlackAndWhiteNN()\n",
    "modelName = '4BlackAndWhiteFirst'\n",
    "\n",
    "argDict = {\n",
    "  'lr': 0.001,\n",
    "  'maxEpoch': 250,\n",
    "  'idleEpoch': 25,\n",
    "  'outputName': modelName,\n",
    "  'optimizer': optim.SGD(model.parameters(), lr=0.001),\n",
    "  'criterion': nn.CrossEntropyLoss()\n",
    "}\n",
    "\n",
    "# setting up the logger\n",
    "loggerName = modelName + '.log'\n",
    "loggerName = os.path.join(argDict['outputName'], loggerName)\n",
    "logger = MyLogger(loggerName)\n",
    "argDict['logger'] = logger\n",
    "\n",
    "# training and saving model to dictionary\n",
    "outputDict = train(model, argDict, train_loader, valid_loader, test_loader)\n",
    "save_dict_to_file(outputDict, argDict['outputName'], argDict['outputName'])\n",
    "\n",
    "# loading the best model, and then sending it off to testing\n",
    "model = load_model_from_file(model, argDict['outputName'], argDict['outputName'])\n",
    "\n",
    "test_accuracy = test(model, test_loader)\n",
    "tempString = 'testing accuracy of ' + argDict['outputName'] + \" is: \" + str(test_accuracy)\n",
    "logger.log(tempString)\n",
    "\n",
    "del model\n",
    "del argDict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = BlackAndWhiteNN()\n",
    "modelName = '5BlackAndWhiteSecondLowerLR'\n",
    "\n",
    "argDict = {\n",
    "    'lr': 0.0005,\n",
    "    'maxEpoch': 250,\n",
    "    'idleEpoch': 25,\n",
    "    'outputName': modelName,\n",
    "    'optimizer': optim.SGD(model.parameters(), lr=0.001),\n",
    "    'criterion': nn.CrossEntropyLoss()\n",
    "}\n",
    "\n",
    "# setting up the logger\n",
    "loggerName = modelName + '.log'\n",
    "loggerName = os.path.join(argDict['outputName'], loggerName)\n",
    "logger = MyLogger(loggerName)\n",
    "argDict['logger'] = logger\n",
    "\n",
    "# training and saving model to dictionary\n",
    "outputDict = train(model, argDict, train_loader, valid_loader, test_loader)\n",
    "save_dict_to_file(outputDict, argDict['outputName'], argDict['outputName'])\n",
    "\n",
    "# loading the best model, and then sending it off to testing\n",
    "model = load_model_from_file(model, argDict['outputName'], argDict['outputName'])\n",
    "\n",
    "test_accuracy = test(model, test_loader)\n",
    "tempString = 'testing accuracy of ' + argDict['outputName'] + \" is: \" + str(test_accuracy)\n",
    "logger.log(tempString)\n",
    "\n",
    "del model\n",
    "del argDict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = BlackAndWhiteNN()\n",
    "modelName = '6BlackAndWhiteThirdHigherLR'\n",
    "\n",
    "argDict = {\n",
    "    'lr': 0.003,\n",
    "    'maxEpoch': 250,\n",
    "    'idleEpoch': 25,\n",
    "    'outputName': modelName,\n",
    "    'optimizer': optim.SGD(model.parameters(), lr=0.001),\n",
    "    'criterion': nn.CrossEntropyLoss()\n",
    "}\n",
    "\n",
    "# setting up the logger\n",
    "loggerName = modelName + '.log'\n",
    "loggerName = os.path.join(argDict['outputName'], loggerName)\n",
    "logger = MyLogger(loggerName)\n",
    "argDict['logger'] = logger\n",
    "\n",
    "# training and saving model to dictionary\n",
    "outputDict = train(model, argDict, train_loader, valid_loader, test_loader)\n",
    "save_dict_to_file(outputDict, argDict['outputName'], argDict['outputName'])\n",
    "\n",
    "# loading the best model, and then sending it off to testing\n",
    "model = load_model_from_file(model, argDict['outputName'], argDict['outputName'])\n",
    "\n",
    "test_accuracy = test(model, test_loader)\n",
    "tempString = 'testing accuracy of ' + argDict['outputName'] + \" is: \" + str(test_accuracy)\n",
    "logger.log(tempString)\n",
    "\n",
    "del model\n",
    "del argDict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('finishedBnW.txt', \"w\") as file:\n",
    "  file.write('donezo')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMPhCe+CPqr8788BodV/T4I",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}